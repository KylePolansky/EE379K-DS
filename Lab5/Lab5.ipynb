{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karthik Konath (kk28699), Kyle Polansky (kpp446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>EE 379K-DS Lab 5<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1: Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.1) Generate 20 random points in d = 3, from a Gaussian multivariate distribution with mean [0, 0, 0] and covariance matrix (...). Let’s call this data with label 1. Also generate 20 random points in d = 3 from another Gaussian with mean [0, 0, 1] and covariance (...). Let’s call that data with label 2. Create a three dimensional plot of the clouds of data points, labeled with the two labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.2) Perform a projection of the data on one dimension using Fischer’s Linear Discriminant as explained in class (see also http://research.cs.tamu.edu/prism/lectures/pr/pr_l10.pdf). (no sklearn Linear Discriminant Analysis functions here, just friendly linear algebra.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1.3) Use sklearn to perform Linear Discriminant Analysis. Compare the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2:  Problem 10 from Chapter 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This question should be answered using the Weekly data set, which is part of the ISLR package. This data is similar in nature to the Smarket data from this chapter’s lab, except that it contains 1,089 weekly returns for 21 years, from the beginning of 1990 to the end of 2010."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.a) Produce some numerical and graphical summaries of the Weekly data. Do there appear to be any patterns?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.b) Use the full data set to perform a logistic regression with Direction as the response and the five lag variables plus Volume as predictors. Use the summary function to print the results. Do any of the predictors appear to be statistically significant? If so, which ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.c) Compute the confusion matrix and overall fraction of correct predictions. Explain what the confusion matrix is telling you about the types of mistakes made by logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.d) Now fit the logistic regression model using a training data period from 1990 to 2008, with Lag2 as the only predictor. Compute the confusion matrix and the overall fraction of correct predictions for the held out data (that is, the data from 2009 and 2010)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.e) Repeat (d) using LDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.f) Repeat (d) using QDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.g) Repeat (d) using KNN with K = 1 ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.h) Which of these methods appears to provide the best results on this data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2.i) Experiment with different combinations of predictors, including possible transformations and interactions, for each of the methods. Report the variables, method, and associated confusion matrix that appears to provide the best results on the held out data. Note that you should also experiment with values for K in the KNN classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3: Problem 5 from Chapter 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chapter 4, we used logistic regression to predict the probability of default using income and balance on the Default data set. We will now estimate the test error of this logistic regression model using the validation set approach. Do not forget to set a random seed before beginning your analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.a) Fit a logistic regression model that uses income and balance to predict default."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.b) Using the validation set approach, estimate the test error of this model. In order to do this, you must perform the following steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.b.i) Split the sample set into a training set and a validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.b.ii) Fit a multiple logistic regression model using only the training observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.b.iii)  Obtain a prediction of default status for each individual in the validation set by computing the posterior probability of default for that individual, and classifying the individual to the default category if the posterior probability is greater than 0.5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.b.iv) Compute the validation set error, which is the fraction of the observations in the validation set that are misclassified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.c) Repeat the process in (b) three times, using three different splits of the observations into a training set and a validation set. Comment on the results obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3.d) Now consider a logistic regression model that predicts the probability of default using income, balance, and a dummy variable for student. Estimate the test error for this model using the validation set approach. Comment on whether or not including a dummy variable for student leads to a reduction in the test error rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4: Problem 8 from Chapter 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now perform cross-validation on a simulated data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.a) Generate a simulated data set as follows ... In this data set, what is n and what is p? Write out the model used to generate the data in equation form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def gen_xy():\n",
    "    global x, y\n",
    "    x = np.random.randn(100)\n",
    "    y = x - 2*(x**2) + np.random.randn(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "n (number of samples): 100  \n",
    "p (number of predictors): 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.b) Create a scatterplot of X against Y . Comment on what you find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nA0Ag/h+4aHEyv8dX9AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2b1642935c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "np.random.seed(1)\n",
    "gen_xy()\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot axis are both centered at 0. Both X and Y are skewed negative. X and Y are correlated by a parabolic relationship."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.c)  Set a random seed, and then compute the LOOCV errors that result from fitting the following four models using least squares:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection  import LeaveOneOut, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import pandas as pd\n",
    "\n",
    "def gen_rand_data():\n",
    "    np.random.seed()\n",
    "    gen_xy()\n",
    "    \n",
    "    global df1, df2, df3, df4\n",
    "    df1 = pd.DataFrame({'x0': np.ones(100), 'x1': x})\n",
    "    df2 = pd.DataFrame({'x0': np.ones(100), 'x1': x, 'x2': x**2})\n",
    "    df3 = pd.DataFrame({'x0': np.ones(100), 'x1': x, 'x2': x**2, 'x3': x**3})\n",
    "    df4 = pd.DataFrame({'x0': np.ones(100), 'x1': x, 'x2': x**2, 'x3': x**3, 'x4': x**4})\n",
    "\n",
    "def get_score(x):\n",
    "    return cross_val_score(LinearRegression(), x, y, cv=LeaveOneOut(), scoring='neg_mean_squared_error')\n",
    "\n",
    "gen_rand_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.c.i) $Y = \\beta_0 + \\beta_1X + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-5.841320240620483\n"
     ]
    }
   ],
   "source": [
    "print(get_score(df1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.c.ii) $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0684136617867015\n"
     ]
    }
   ],
   "source": [
    "print(get_score(df2).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.c.iii) $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.0938894020584464\n"
     ]
    }
   ],
   "source": [
    "print(get_score(df3).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.c.iv) $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\beta_3X^3 + \\beta_4X^4 + \\epsilon$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1.1441447401762184\n"
     ]
    }
   ],
   "source": [
    "print(get_score(df4).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.d) Repeat (c) using another random seed, and report your results. Are your results the same as what you got in (c)? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-11.758590683410386\n",
      "-1.0253673207743532\n",
      "-1.0438883706278488\n",
      "-1.0401764795637651\n"
     ]
    }
   ],
   "source": [
    "gen_rand_data()\n",
    "\n",
    "print(get_score(df1).mean())\n",
    "print(get_score(df2).mean())\n",
    "print(get_score(df3).mean())\n",
    "print(get_score(df4).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are different since the data is randomly seeded, however the trends are the same, as described below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.e) Which of the models in (c) had the smallest LOOCV error? Is this what you expected? Explain your answer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The 2nd model of the form $Y = \\beta_0 + \\beta_1X + \\beta_2X^2 + \\epsilon$ had the smallest error.  \n",
    "\n",
    "This was expected because the generated y's are based off an equation of the form $x^2$. The first model would have created a linear underfit and the 3rd and 4th models would have overfit, resulting in a lower test score."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4.f)  Comment on the statistical significance of the coefficient estimates that results from fitting each of the models in (c) using least squares. Do these results agree with the conclusions drawn based on the cross-validation results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00000000e+00  1.07420037e+00 -1.80258636e+00 -6.79262095e-04\n",
      " -4.49816832e-02]\n"
     ]
    }
   ],
   "source": [
    "regression = LinearRegression().fit(X=df4, y=y)\n",
    "print(regression.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, the coefficients model the equation very well. The coefficients show a 1:1 relationship with x and about a -2 relationship with $x^2$. $x^3$ and $x^4$ contribute very little to the model, and we can see very little difference in error scores above when those are used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
