Supplementary Material: Deep Generative Models for Relational Data with

Side Information

1. Proof of Lemma 1
We can compute E[I{Aij = 0}] as
E[I{Aij = 0}] = p(Xij = 0)

= Ezi,zj ,Λ

p(Xij = 0|zik1, zjk2 , Λk1k2)





k1,k2

k1,k2=1

 K(cid:89)
 K(cid:89)
log
− K(cid:88)
(cid:105)
− K(cid:88)
(cid:20) ζγc

k1,k2=1

k1,k2=1

γbck1k2

≥ exp

Ezi,zj ,Λ

exp(−Λk1k2zik1zjk2)

= Ezi,zj ,Λ

(cid:18)

= Ezi,zj ,Λ

exp(−Λk1k2zik1 zjk2)
K(cid:89)

k1,k2=1

Λk1k2 zik1zjk2



(cid:19)

(1)



(cid:21)

E(cid:104)(cid:80)K

where the inequality step follows from Jensen’s inequal-
(Zhou, 2015), we have
ity.
+ γ2
. Then the last

Following Lemma 1 in
= ζγc
k1,k2=1 Λk1k2

γ2
b ck1 k2
line in Equation (1) can be written as

γbck1k2

a

Ezi,zj ,Λ

= exp

(cid:18)

−

Λk1k2 zik1zjk2

+

γ2
a
γ2
b ck1k2

E
z(1)
i z(1)

j

(2)

(cid:105)(cid:19)

(cid:104)

z(1)
ik1

z(1)
jk2

Based on Equation (1) and (3), the expected number of ze-
ros in A is lower bounded by

N(cid:88)

E[

i,j=1

I{Aij = 0}] ≥ N 2Ezi,zj ,Λ
(cid:32)

(cid:34)

= N 2 exp

−

ζγc

+

γ2
a

− K(cid:88)
(cid:35)

E

k1,k2=1

(cid:104)



(cid:105)(cid:33)

γbck1 k2

γ2
b ck1k2

z

(1)
i

z

(1)
j

z(1)
ik1

z(1)
jk2

(3)

Λk1k2 zik1 zjk2

2. HYPERPARAMETER INFERENCE
We sample w((cid:96))
k and mk leveraging the P´olya-Gamma
augmentation (Polson et al., 2013). This enables us to de-

k , b((cid:96))

. Correspondence to: Changwei Hu <changweih@yahoo-
inc.com>, Piyush Rai <piyush@cse.iitk.ac.in>, Lawrence Carin
<lcarin@duke.edu>.

k

k,(cid:96) and Γ(m)
k and b((cid:96))

rive the Gibbs sampler updates for the hyper-parameters
γk1, ξ, Γ(w)

, in closed form.

Sample w((cid:96))
k : We consider the update of layer-1
weights w(1)
as an example, and assume the side informa-
k
tion is available (which is the more general case). Weights
for the other layers can be sampled in a similar manner.

Given the P´olya-Gamma auxiliary variables α(1)
terior for w(1)

k will be w(1)

, V(w)

k , the pos-
), where

k

k ∼ N (µ(w)
k − 1
k )Z(2) + (Γ(w)
k,(cid:96) )

k
1N − diag(α(1)
k )(Smk + b(1)
−1
−1)

2

k 1N ))

µ(w)

k

V(w)

k

= V(w)

k

(Z(2))T (z(2)

= ((Z(2))T diag(α(1)

k ∈ RN

In the above, 1N is a vector of length N with all entries
being 1, and α(1)
ik is drawn from the
P´olya-Gamma distribution
ik ∼ PG(1, mT
α(1)

+ , each entry α(1)

k si + (w(1)

k )(cid:62)z(2)

i + b(1)
k )

Conditioned on these PG variables, the posterior over b((cid:96))
k
will also be a Gaussian.
Sample mk: Akin to the way we sample w((cid:96))
k , the side in-
formation based regression weights mk can also be sam-
pled using the P´olya-Gamma scheme (using the layer 1
PG variables α(1)
k ). The posterior will be a Gaussian
mk ∼ N (µ(m)
, V(m)

), where

k

k

µ(m)

k

V(m)

k

= V(m)

k ST (z(2)

= ((ST diag(α(1)

k − 1
k )S + (Γ(m)

1N − diag(α(1)
k )(Z(2)w(1)
−1

−1)

2

)

k

k + b(1)

k 1N ))

Sample γk1: γk1 can be sampled as

γb −(cid:80)

ξδk1k2 γ

k2

1

1−δk1k2
k2

ln(

ck1 k2

Qk1 k2

+ck1k2

)

)

γk1 ∼ Gamma(γa+(cid:96)k1k2 ,

where (cid:96)k1· = (cid:80)

k2

nese Restaurant Table (CRT) distribution (Zhou, 2015)

(cid:96)k1k2 with (cid:96)k1k2 drawn from the Chi-

(cid:96)k1k2 ∼ CRT(X··k1k2, gk1k2)

Sample ξ: The hyperparameter ξ can be sampled as

(cid:88)

k

ξb −(cid:80)

(cid:96)kk,

1

k γk ln(

ckk

Qkk+ckk

)

)

Proceedings of the 34 th International Conference on Machine
Learning, Sydney, Australia, PMLR 70, 2017. Copyright 2017
by the author(s).

ξ ∼ Gamma(ξa +

Supplementary Material: Deep Generative Models for Relational Data with Side Information

Sample Γ(w)
matrix Γ(w)

k,(cid:96) , Γ(m)
k,(cid:96) is sampled as

k

: Each diagonal entry of the precision

k,(cid:96)∼Gamma(a+
Γ(w)

K(cid:96)+1

2

,

1
diag((b + 0.5(w((cid:96))
k )T w((cid:96))

k )1K(cid:96)+1)

)

where a and b are the scale and rate parameters for the prior
of Γ(w)

can be sampled similarly.

k,(cid:96) respectively. Γ(m)

k

References
Polson, Nicholas G, Scott, James, and Windle, Jesse.
Bayesian inference for logistic models using p´olya–
gamma latent variables. Journal of the American Sta-
tistical Association, 108(504):1339–1349, 2013.

Zhou, Mingyuan. Inﬁnite edge partition models for over-
In

lapping community detection and link prediction.
AISTATS, 2015.

