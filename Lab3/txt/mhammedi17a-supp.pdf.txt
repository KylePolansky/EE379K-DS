A. Proofs
Sketch of the proof for Theorem 1. We need to the show
that for every ˜Q ∈ O(n), there exits a tuple of vec-
tors (u1, . . . , un) ∈ R × ··· × Rn such that ˜Q =
M1(u1, . . . , un). Algorithm 1 shows how a QR decompo-
sition can be performed using the matrices {Hk(uk)}n
k=1
while ensuring that the upper triangular matrix R has pos-
itive diagonal elements. If we apply this algorithm to an
orthogonal matrix ˜Q, we get a tuple (u1, . . . , un) which
satisﬁes

QR = Hn(un) . . .H1(u1)R = ˜Q.

Note that the matrix R must be orthogonal since R = Q(cid:48) ˜Q.
Therefore, R = I, since the only upper triangular ma-
trix with positive diagonal elements is the identity matrix.
Hence, we have

M1(u1, . . . , un) = Hn(un) . . .H1(u1) = ˜Q.

Algorithm 1 QR decomposition using the mappings {Hk}.
For a matrix B ∈ Rn×n, {Bk,k}1≤k≤n denote its diagonal
elements, and Bk..n,k = (Bk,k, . . . , Bn,k)(cid:48) ∈ Rn−k+1.
Require: A ∈ Rn×n is a full-rank matrix.
Ensure: Q and R where Q = Hn(un) . . .H1(u1) and R
is upper triangular with positive diagonal elements such
that A = QR
R ← A
Q ← I {Initialise Q to the identity matrix}
for k = 1 to n − 1 do

if Rk,k == (cid:107)Rk..n,k(cid:107) then

else

un−k+1 = (0, . . . , 0, 1)(cid:48) ∈ Rn−k+1
un−k+1 ← Rk..n,k − (cid:107)Rk..n,k(cid:107) (1, 0, . . . , 0)(cid:48)
un−k+1 ← un−k+1/(cid:107)un−k+1(cid:107)

end if
R ← Hn−k+1(un−k+1)R
Q ← QHn−k+1(un−k+1)

end for
u1 = sgn(Rn,n) ∈ R
R ← H1(u1)R
Q ← QH1(u1)

where dA, dB, and dC represent inﬁnitesimal perturba-
tions and

(cid:20) ∂C

(cid:21)(cid:48)

∂B

∂L
∂C

.

(cid:20) ∂C

(cid:21)(cid:48)

∂A

C :=

∂L
∂C

, A :=

∂L
∂C

, B :=

Proof of Theorem 2. Let C = h − U T −1U(cid:48)h where
(U, h) ∈ Rn×m × Rn and T = striu(U(cid:48)U ) + 1
2diag(U(cid:48)U ).
Notice that the matrix T can be written using the Hadamard
product as follows

T = B ◦ (U(cid:48)U ),

(1)
2 Im and Jm is the m × m matrix

where B = striu(Jm) + 1
of all ones.
Calculating the inﬁnitesimal perturbations of C gives

dC =(I − U T −1U(cid:48))dh

− dU T −1U(cid:48)h − U T −1dU(cid:48)h
+ U T −1dT T −1U(cid:48)h.

Using Equation (1) we can write

dT = B ◦ (dU(cid:48)U + U(cid:48)dU ).

By substituting this back into the expression of dC, multi-
, and applying the
plying the left and right-hand sides by C
trace we get

(cid:48)

(cid:48)

Tr(C

dC) = Tr(C
− Tr(C
+ Tr(C

(cid:48)
(cid:48)

(cid:48)

(I − U T −1U(cid:48))dh)
(cid:48)

dU T −1U(cid:48)h) − Tr(C
U T −1(B ◦ (dU(cid:48)U + U(cid:48)dU ))T −1U(cid:48)h).

U T −1dU(cid:48)h)

Now using the identity Tr(AB) = Tr(BA), where the sec-
ond dimension of A agrees with the ﬁrst dimension of B,
we can rearrange the expression of Tr(C
(I − U T −1U(cid:48))dh)
(cid:48)
dU ) − Tr(hC
U T −1(B ◦ (dU(cid:48)U + U(cid:48)dU ))).

dC) = Tr(C
− Tr(T −1U(cid:48)hC
+ Tr(T −1U(cid:48)hC

U T −1dU(cid:48))

dC) as follows

Tr(C

(cid:48)
(cid:48)

(cid:48)

(cid:48)

(cid:48)

To simplify the expression, we will use the short notations

˜C = (T (cid:48))−1U(cid:48)C,
˜h = T −1U(cid:48)h,

Lemma 1. (Giles, 2008) Let A, B, and C be real or com-
plex matrices, such that C = f (A, B) where f is some dif-
ferentiable mapping. Let L be some scalar quantity which
depends on C. Then we have the following identity

(cid:48)

Tr(C

dC) = Tr(A

(cid:48)

dA) + Tr(B

(cid:48)

dB),

(cid:48)

Tr(C

dC) becomes

Tr(C

(cid:48)

(cid:48) − ˜C(cid:48)U(cid:48))dh)
(cid:48)
dU ) − Tr(h ˜C(cid:48)dU(cid:48))

dC) = Tr((C
− Tr(˜hC
+ Tr(˜h ˜C(cid:48)(B ◦ (dU(cid:48)U + U(cid:48)dU ))).

Now using the two following identities of the trace

Tr(A(cid:48)) = Tr(A),

Tr(A(B ◦ C)) = Tr((A ◦ B(cid:48))C)),

we can rewrite Tr(C

(cid:48)

dC) as follows

(cid:48)

Tr(C

dC) =Tr((C

(cid:48) − ˜C(cid:48)U(cid:48))dh)

(cid:48)

dU ) − Tr(h ˜C(cid:48)dU(cid:48))

− Tr(˜hC
+ Tr((˜h ˜C(cid:48) ◦ B(cid:48))dU(cid:48)U )
+ Tr((˜h ˜C(cid:48) ◦ B(cid:48))U(cid:48)dU ).

By rearranging and taking the transpose of the third and
fourth term of the right-hand side we obtain

(cid:48)

Tr(C

dC) =Tr((C

(cid:48) − ˜C(cid:48)U(cid:48))dh)

(cid:48)

dU ) − Tr( ˜Ch(cid:48)dU )

− Tr(˜hC
+ Tr((( ˜C˜h(cid:48)) ◦ B)U(cid:48)dU )
+ Tr(((˜h ˜C(cid:48)) ◦ B(cid:48))U(cid:48)dU ).

(cid:48)

Tr((˜hC

Factorising by dU inside the Tr we get
(cid:48) − ˜C(cid:48)U(cid:48))dh)−

dC) = Tr((C

Tr(C

(cid:48)

+ ˜Ch(cid:48) −(cid:104)
(cid:104)

( ˜C˜h(cid:48)) ◦ B + (˜h ˜C(cid:48)) ◦ B(cid:48)(cid:105)
(cid:105) − C˜h(cid:48) − h ˜C(cid:48),

(˜h ˜C(cid:48)) ◦ B(cid:48) + ( ˜C˜h(cid:48)) ◦ B

U(cid:48))dU ).

Using lemma 1 we conclude that

U =U
h =C − U ˜C.

Sketch of the proof for Corollary 1. For any nonzero com-
plex valued vector x ∈ Cn, if we chose u = x + eiθ (cid:107)x(cid:107) e1
(cid:107)u(cid:107)2 ), where θ ∈ R is such that
and H = −e−iθ(I − 2 uu∗
x1 = eiθ|x1|, we have (Mezzadri, 2006)

Hx = ||x||e1

(2)

Taking this fact into account, a similar argument to that
used in the proof of Theorem 1 can be used here.

B. Algorithm Explanation
Let U := (vi,j)1≤j≤m
T := striu(U(cid:48)U ) + 1

1≤i≤n . Then the element of the matrix

2diag(U(cid:48)U ) can be expressed as

(cid:80)n

ti,j =(cid:74)i ≤ j(cid:75)

k=j vk,ivk,j
1 + δi,j

,

where δi,j is the Kronecker delta and (cid:74)·(cid:75) is the Iversion
bracket (i.e.(cid:74)p(cid:75) = 1 if p is true and(cid:74)p(cid:75) = 0 otherwise).

In order to compute the gradients in Equations (14) and
(15). we ﬁrst need to compute ˜h = T −1U(cid:48)h and ˜C =
(T (cid:48))−1U(cid:48) ∂L
∂C . This is equivalent to solving the triangular
systems of equations T ˜h = U(cid:48)h and T (cid:48) ˜C = U(cid:48) ∂L
∂C .
Solving the triangular system T ˜h = U(cid:48)h. For 1 ≤ k ≤
m, we can express the k-th row of this system as

tk,k

˜hk +

=

=

j=k+1

j=k

tk,j

˜hj =

m(cid:88)
n(cid:88)
n(cid:88)
vj,khj − m(cid:88)
n(cid:88)
vr,khr − n(cid:88)
∗,k(h − m(cid:88)

r=k

j=k

j=k+1

r=k+1

= U(cid:48)

vj,khj,

n(cid:88)

r=j

vr,k

vr,kvr,j

˜hj,

r(cid:88)

vr,j

˜hj,

(3)

j=k+1

˜hj),

(4)

U∗,j

j=k+1

where the passage from Equation (3) to (4) is justiﬁed be-
˜hj =

cause vr,j = 0 for j > r. Therefore,(cid:80)r
(cid:80)m
By setting H∗,k+1 := h −(cid:80)m

˜hj, and noting that

j=k+1 vr,j

j=k+1 vr,j

j=k+1 U∗,j

˜hj.

tk,k =

U(cid:48)
∗,kU∗,k

2

, we get

2

U(cid:48)
∗,kH∗,k+1,

U(cid:48)
∗,kU∗,k

˜hk =
H∗,k = H∗,k+1 − ˜hkU∗,k.

(5)

(6)

rithm 1. Note that H∗,1 = h −(cid:80)m
(cid:80)m
Equations (5) and (6) explain the lines 8 and 9 in Algo-
˜hj = h −
j=1 U∗,j[T −1U(cid:48)h]j = h − U T −1U(cid:48)h = W h. Hence,
when h = h(t−1), we have H∗,1 = C (t), which explains
line 16 in Algorithm 1.
Solving the triangular system T (cid:48) ˜C = U(cid:48) ∂L
the previous case, we have for 1 ≤ k ≤ m

∂C . Similarly to

j=1 U∗,j

tk,k ˜Ck +

=

=

j=1

k−1(cid:88)
n(cid:88)
n(cid:88)

j=1

vj,k

tj,k ˜Cj =

j

,

j=k

∂C

vj,k

(cid:21)

(cid:20) ∂L
n(cid:88)
(cid:21)
(cid:20) ∂L
n(cid:88)
− k−1(cid:88)
(cid:20) ∂L
(cid:21)
k−1(cid:88)
− n(cid:88)
 ∂L
 ,
− k−1(cid:88)

U∗,j ˜Cj

vr,k

∂C

∂C

r=k

r=1

j=1

j=1

r

j

vr,k

∂C

j=1

r=1

= U(cid:48)
∗,k

vr,jvr,k ˜Cj,

(7)

vr,j ˜Cj,

(8)

Operation

FP

BP

˜hk ← 2

U(cid:48)
∗,kH∗,k+1

H∗,k ← H∗,k+1 − ˜hkU∗,k

Nk

˜hk ← 2

U(cid:48)
∗,kH∗,k+1

Nk

g ← g − ˜CkU∗,k

G∗,k ← −˜hkg − ˜CkH∗,k+1

Flop count
for iteration k
2(n − k) + 3

2n

2(n − k) + 3
2(n − k + 1)

3n

Total Flop count
for m iteration
(4n − m + 2)m

(7n − 2m + 3)m

Table 1. Time complexities of different operations in algorithm 1. It is assumed that the matrix U ∈ Rn×m is deﬁned as in Equation (9).

the fact that(cid:80)n

r=k vr,jvr,k ˜Cj = (cid:80)n
∂C(t) − (cid:80)k−1

where the passage from Equation (7) to (8) is justiﬁed by
r=1 vr,jvr,k ˜Cj (since

vr,k = 0 for r < k).
By setting g := ∂L
j=1 U∗,j ˜Cj, we can write
U(cid:48)
˜Ck =
∗,kg which explains the lines 12 and
13 in Algorithm 1. Note also that after m-iterations in
the backward propagation loop in Algorithm 1, we have
j=1 U∗,j ˜Cj = ∂L
g = ∂L
∂h(t−1) . This
explains line 17 of Algorithm 1.
Finally, note that from Equation (14), we have for 1 ≤ i ≤
n and 1 ≤ k ≤ m

∂C(t) − U ˜C = ∂L

U(cid:48)
∗,kU∗,k

2

j=1

∂U

i,k

∂C

i

∂C

i

vi,j

= −

= −

˜hk − hi ˜Ck+

˜hk − hi ˜Ck+

∂C(t) −(cid:80)m
(cid:20) ∂L
(cid:20) ∂L
(cid:21)
(cid:21)
(cid:16)
m(cid:88)
(cid:21)
(cid:20) ∂L
(cid:18)
m(cid:88)
˜hj ˜Ck(cid:74)k ≤ j(cid:75)
(cid:21)
(cid:20) ∂L
(cid:16)˜hj ˜Ck(cid:74)k < j(cid:75) + ˜Cj
m(cid:88)
 m(cid:88)

 k(cid:88)
(cid:20) ∂L
(cid:21)
(cid:21)

1 + δj,k
˜hk − hi ˜Ck+

vi,j ˜Cj −

˜hj − hi

= −

+ ˜hk

= ˜Ck

j=k+1

vi,j

∂C

i

vi,j

vi,j

j=1

j=1

j=1

∂C

i

+ ˜Cj

(cid:20) ∂L
∂C(t) −(cid:80)k−1

∂U (t)

∗,k

j=1

where g = ∂L
and 18 of Algorithm 1.

Therefore, when C = C (t) and h = h(t−1) we have

= − ˜CkH∗,k+1 − ˜hkg,

˜CjU∗,j. This explains lines 14

((˜h ˜C(cid:48)) ◦ B(cid:48))j,k + (( ˜C˜h(cid:48)) ◦ B)j,k

(cid:17)

,

(cid:19)

,

,

1 + δj,k

˜hk(cid:74)j ≤ k(cid:75)
˜hk(cid:74)j ≤ k(cid:75)(cid:17)
 .

C. Time complexity
Table 1 shows the ﬂop count for different operations in the
local backward and forward propagation steps in Algorithm
1.

D. Matlab implementation of Algorithm 1

% Inputs: U - matrix of reflection vectors
h - hidden state at time-step t-1
%
%
BPg - Grad of loss w.r.t C=Wh
% Outputs: g, G, C=Wh
[n, m] = size(U);
G=zeros(n, m); H = zeros(n, m+1);
N = zeros(m); h_tilde = zeros(m);
%
H(:,m+1)=h; g=BPg;
%%--Forward propagation--%%
for k =0:m-1

Zero-initialisation not required above!

N(m-k) = U(:, m-k)' * U(:, m-k);
h_tilde(m-k)=2 / N(m-k) * ...

U(:, m-k)' * H(:,m-k+1);

H(:,m-k)=H(:,m-k+1) - ...

h_tilde(m-k) * U(:,m-k);

end
C = H(:,1)
%%--Backward propagation--%%
for k=1:m

c_tilde_k = 2*U(:,k)' * g / N(k);
g = g - c_tilde_k * U(:,k);
G(:, k)=-h_tilde(k) * g - ...

c_tilde_k*H(:,k+1);

end

∂L

Figure 1. MATLAB code performing one-step FP and BP re-
∂h(t−1) (variable g is the code), and
quired to compute C (t),
∂L
∂U (t) (variable G is the code). The required inputs for the FP and
BP are, respectively, the tuples (U, h(t−1)) and (U, C (t), ∂L
∂C(t) ).
Note that

∂L
∂C(t) is variable BPg in the Matlab code.

References
Giles, Mike B. An extended collection of matrix derivative
results for forward and reverse mode automatic differen-
tiation. 2008.

Mezzadri, Francesco. How to generate random matrices
from the classical compact groups. arXiv preprint math-
ph/0609050, 2006.

