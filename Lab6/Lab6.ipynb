{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karthik Konath (kk28699), Kyle Polansky (kpp446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>EE 379K-DS Lab 6<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem we will use synthetic data sets to explore the bias-variance tradeoff incurred by using regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data of the form: $y=Xβ+\\epsilon$, where X is an n×p matrix where n= 51,p= 50, and each $X_{ij}$ ∼N(0,1). Also, generate the noise according to $\\epsilon_i$ ∼N(0,1/4). Let β be the all ones vector (for simplicity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By repeatedly doing this experiment and generating fresh data (fresh X, and y, and hence $\\epsilon$ – but make that you’re not reseting your random seed!) but keeping β fixed, you will estimatemany different solutions,ˆβ.  Estimate the mean and variance of ˆβ. Note that ˆβ is a vector, so for this exercise simply estimate the variance of a single component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean:  -0.3513087670878969\n",
      "Variance:  11.765113309006235\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, LeaveOneOut\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "bhat = []\n",
    "\n",
    "for i in range(1000):\n",
    "    x = np.random.randn(51,50)\n",
    "    e = np.asarray([np.random.normal(0,.25,51)]).transpose()\n",
    "    b = np.ones(50).transpose()\n",
    "    y = np.dot(x, b) + e\n",
    "    \n",
    "    fit = LinearRegression().fit(x,y)\n",
    "    bhat.append(fit.coef_[0,0])\n",
    "\n",
    "print(\"Mean: \", np.mean(bhat))\n",
    "print(\"Variance: \", np.var(bhat))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ridge regression, i.e., l2 regularization. Vary the regularization coefficient λ= 0.01,0.1,1,10,100 and repeat the above experiment. What do you observe? As you increase λ is the model becoming more simple or more complex? As you increase λ is performance becoming better or worse? Also compute LOOCV for each λ. How does the value of LOOCV, and in particular how it changes as λ varies, compare with what you observe for the explicitly computed variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.01 mean:  0.04210509697234493 variance: 5.852744288755671e-29 rmse: 0.004267142701373676 LOOCV: 0.315668622323263\n",
      "alpha: 0.1 mean:  -0.017421271808952584 variance: 1.180338265250124e-30 rmse: 0.008554739735711426 LOOCV: 0.18830953475685752\n",
      "alpha: 1 mean:  -0.13863892935389355 variance: 2.8926712498051423e-32 rmse: 0.05453718819459226 LOOCV: 0.3892386871092322\n",
      "alpha: 10 mean:  0.02910249644399795 variance: 2.2794891425112652e-33 rmse: 0.11255486349382784 LOOCV: 0.24406365386326734\n",
      "alpha: 100 mean:  -0.0009539587031071637 variance: 1.8616304033972567e-34 rmse: 0.20511361219723612 LOOCV: 0.22296113024832562\n"
     ]
    }
   ],
   "source": [
    "alphas = [0.01,0.1,1,10,100]\n",
    "\n",
    "for alpha in alphas:\n",
    "    x = np.random.randn(51,50)\n",
    "    e = np.asarray([np.random.normal(0,.25,51)]).transpose()\n",
    "    b = np.ones(50).transpose()\n",
    "    y = np.dot(x, b) + e\n",
    "    \n",
    "    fit = Ridge(alpha).fit(x,y)\n",
    "    mean = np.mean(fit.coef_[:,0])\n",
    "    var = np.var(fit.coef_[:,0])\n",
    "    \n",
    "    y_pred = fit.predict(x)\n",
    "    \n",
    "    rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "    \n",
    "    loo = LeaveOneOut()\n",
    "    loo_score = 0\n",
    "    for train_index, test_index in loo.split(x):\n",
    "        x_train, x_test = x[train_index], x[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        \n",
    "        fit = Ridge(alpha=alpha).fit(x_train, y_train)\n",
    "        y_pred = fit.predict(x_test)\n",
    "        \n",
    "        loo_score += np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "\n",
    "    \n",
    "    print(\"alpha:\", alpha, \"mean: \", mean, \"variance:\", var, \"rmse:\", rmse, \"LOOCV:\", loo_score/loo.get_n_splits(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read about the Bootstrap, and try to use it to compute the variance (as above), but with asingle copy of the data, rather than with many fresh copies of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population Mean: -1.0964582685772777\n",
      "Population Variance: 65.7236986872865\n",
      "Bootstrap Mean: -1.0993340223690444\n",
      "Bootstrap Variance: 66.30754449305515\n"
     ]
    }
   ],
   "source": [
    "import bootstrapped.bootstrap as bs\n",
    "import bootstrapped.stats_functions as bs_stats\n",
    "\n",
    "x = np.random.randn(51,50)\n",
    "e = np.asarray([np.random.normal(0,.25,51)]).transpose()\n",
    "b = np.ones(50).transpose()\n",
    "y = np.dot(x, b) + e\n",
    "\n",
    "samples = y.flatten();\n",
    "\n",
    "print(\"Population Mean:\", np.mean(samples))\n",
    "print(\"Population Variance:\", np.var(samples))\n",
    "\n",
    "bs_mean = bs._bootstrap_sim(samples, bs_stats.mean, None, 10, 100, None)\n",
    "bs_std = bs._bootstrap_sim(samples, bs_stats.std, None, 10, 100, None)\n",
    "\n",
    "print(\"Bootstrap Mean:\", np.mean(bs_mean))\n",
    "print(\"Bootstrap Variance:\", np.mean(np.square(bs_std)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. Problem 9 from Chapter 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Predicting  the  number  of  applications  in  College)  Note  that  you  will  have  to  read  about  PCR(Principal Components Regression) and PLS (Partial Least Squares ) in the book, since we did notdiscuss these in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this exercise, we will predict the number of application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Split the data set into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"College.csv\", header = 0, index_col = 0)\n",
    "df.head()\n",
    "\n",
    "df.replace({\"Yes\" : 1, \"No\" : 0}, inplace = True)\n",
    "x = df.drop([\"Apps\"], axis = 1)\n",
    "y = df.loc[:,\"Apps\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Fit a linear model using least squares on the training set, and report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010.6636061663704\n"
     ]
    }
   ],
   "source": [
    "fit = LinearRegression().fit(x_train, y_train)\n",
    "y_pred = fit.predict(x_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Fit a ridge regression model on the training set, with λ chosen by cross-validation. Report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012.8559499061809\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0.001,10,.01)\n",
    "fit = RidgeCV(alphas = alphas).fit(x_train, y_train)\n",
    "y_pred = fit.predict(x_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Fit a lasso model on the training set, with λ chosen by crossvalidation. Report the test error obtained, along with the number of non-zero coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014.3092155895241\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "fit = LassoCV(alphas = alphas).fit(x_train, y_train)\n",
    "y_pred = fit.predict(x_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print(sum(fit.coef_ > 0.1) + sum(fit.coef_ < -0.1)) #coefficients less than .1 considered 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Fit a PCR model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value of M selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046.6227708719919\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "total_variance = 0\n",
    "\n",
    "for i in range(1,18):\n",
    "    pca = PCA(n_components = i, svd_solver = \"full\")\n",
    "    score = -1 * cross_val_score(pca, x, y, cv = 5).mean()\n",
    "    pca  = pca.fit(x_train, y_train)\n",
    "    if total_variance < .9:\n",
    "        total_variance += pca.explained_variance_ratio_[-1]\n",
    "        m = i\n",
    "\n",
    "fit = LinearRegression().fit(x_train.iloc[:,:m+1] , y_train)\n",
    "x_test_pcr = x_test.iloc[:,:m+1]\n",
    "y_pred = pcr.predict(x_test_pcr)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Fit a PLS model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value of M selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028.1645714290194\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in range(1,18):\n",
    "    score = -1 * cross_val_score(PLSRegression(n_components = i), x, y, cv = 5).mean()\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        m = i\n",
    "    \n",
    "fit = PLSRegression(n_components = m).fit(x_train, y_train)\n",
    "y_pred = fit.predict(x_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much difference among the test errors resulting from these five approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the models are roughly similar, with the exception of PLS which is significantly worse than the other models. In our case, the linear model has the lest rmse value, very closely followed by ridge and lasso. Using the linear model, college applications received can be estimated with a RMSE of roughly 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3. Problem 11 from Chapter 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Predicting crime in Boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to predict per capita crime rate in the Boston data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Try out some of the regression methods explored in this chapter, such as best subset selection, the lasso, ridge regression, and PCR. Present and discuss results for the approaches that you consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(254,)\n",
      "('Processed ', 13, 'models on', 1, 'predictors in', 0.03861689567565918, 'seconds.')\n",
      "('Processed ', 78, 'models on', 2, 'predictors in', 0.20980405807495117, 'seconds.')\n",
      "('Processed ', 286, 'models on', 3, 'predictors in', 0.8280420303344727, 'seconds.')\n",
      "('Processed ', 715, 'models on', 4, 'predictors in', 1.910106897354126, 'seconds.')\n",
      "('Processed ', 1287, 'models on', 5, 'predictors in', 3.3881428241729736, 'seconds.')\n",
      "('Processed ', 1716, 'models on', 6, 'predictors in', 4.733531951904297, 'seconds.')\n",
      "('Processed ', 1716, 'models on', 7, 'predictors in', 4.752110958099365, 'seconds.')\n",
      "('Processed ', 1287, 'models on', 8, 'predictors in', 3.605592966079712, 'seconds.')\n",
      "('Processed ', 715, 'models on', 9, 'predictors in', 2.0500900745391846, 'seconds.')\n",
      "('Processed ', 286, 'models on', 10, 'predictors in', 0.8250260353088379, 'seconds.')\n",
      "('Processed ', 78, 'models on', 11, 'predictors in', 0.23470401763916016, 'seconds.')\n",
      "('Processed ', 13, 'models on', 12, 'predictors in', 0.04016613960266113, 'seconds.')\n",
      "('Total elapsed time:', 22.650835037231445, 'seconds.')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import time\n",
    "import statsmodels.api as sm\n",
    "def processSubset(feature_set):\n",
    "    model = sm.OLS(y.loc[:2*len(X)/3],X.loc[:2*len(X)/3][list(feature_set)])\n",
    "    regr = model.fit()\n",
    "    RSS = ((regr.predict(X.loc[2*len(X)/3:][list(feature_set)]) - y.loc[2*len(X)/3:]) ** 2).sum()\n",
    "    return {\"model\":regr, \"RSS\":RSS}\n",
    "\n",
    "def getBest(k):\n",
    "    tic = time.time()\n",
    "    results = []\n",
    "    for combo in itertools.combinations(X.columns, k):\n",
    "        results.append(processSubset(combo)) # Wrap everything up in a nice dataframe\n",
    "    models = pd.DataFrame(results)\n",
    "    # Choose the model with the best residual sum of squares\n",
    "    best_model = models.loc[models['RSS'].argmin()]\n",
    "    toc = time.time()\n",
    "    print(\"Processed \", models.shape[0], \"models on\", k, \"predictors in\", (toc-tic), \"seconds.\")\n",
    "    return best_model\n",
    "\n",
    "models = pd.DataFrame(columns=[\"RSS\", \"model\"])\n",
    "df = pd.read_csv(\"Boston.csv\")\n",
    "y = df.crim\n",
    "X = df.drop(['crim'],axis=1)\n",
    "tic = time.time()\n",
    "print y.loc[:len(X)/2].shape\n",
    "for i in range(1,13):\n",
    "    models.loc[i] = getBest(i)\n",
    "toc = time.time()\n",
    "print(\"Total elapsed time:\", (toc-tic), \"seconds.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AIC: \n",
      "1     665.984995\n",
      "2     631.896265\n",
      "3     633.615819\n",
      "4     632.771619\n",
      "5     633.438532\n",
      "6     555.643732\n",
      "7     556.293212\n",
      "8     500.300291\n",
      "9     473.286494\n",
      "10    461.542683\n",
      "11    451.360659\n",
      "12    440.798575\n",
      "dtype: float64\n",
      "BIC: \n",
      "1     669.808041\n",
      "2     639.542357\n",
      "3     645.084957\n",
      "4     648.063803\n",
      "5     652.553761\n",
      "6     578.582007\n",
      "7     583.054533\n",
      "8     530.884658\n",
      "9     507.693907\n",
      "10    499.773142\n",
      "11    493.414164\n",
      "12    486.675126\n",
      "dtype: float64\n",
      "R^2: \n",
      "1     0.296980\n",
      "2     0.368174\n",
      "3     0.368698\n",
      "4     0.373988\n",
      "5     0.376452\n",
      "6     0.507573\n",
      "7     0.509537\n",
      "8     0.586865\n",
      "9     0.620849\n",
      "10    0.635957\n",
      "11    0.648844\n",
      "12    0.661656\n",
      "dtype: float64\n",
      "RSS: \n",
      "1     37268.864142\n",
      "2     33220.789371\n",
      "3     33366.549965\n",
      "4     33691.621669\n",
      "5     34409.081874\n",
      "6     34398.436365\n",
      "7     34538.955333\n",
      "8     34643.154583\n",
      "9     34952.607655\n",
      "10    35686.296590\n",
      "11    36041.248575\n",
      "12    36432.839014\n",
      "Name: RSS, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print \"AIC: \\n\", models.apply(lambda row: row[1].aic, axis=1)\n",
    "print \"BIC: \\n\", models.apply(lambda row: row[1].bic, axis=1)\n",
    "print \"R^2: \\n\", models.apply(lambda row: row[1].rsquared, axis=1)\n",
    "print \"RSS: \\n\",models[\"RSS\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on R^2 and RSS, you generally get continuously better results as you increase predictor count. However, attempting to minimize AIC and BIC cause us to want to choose a smaller predictor count in order to reduce potential for overfitting among other concerns. In this case, however, AIC and BIC continiously decrease across the 12 features we have, so we feel comfortable using all 12 without too significant of worries about overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zn        -0.001278\n",
      "indus      0.029043\n",
      "chas       0.044097\n",
      "rm         0.166329\n",
      "age        0.002430\n",
      "dis       -0.005937\n",
      "rad        0.023421\n",
      "tax        0.001935\n",
      "ptratio   -0.047123\n",
      "black     -0.003340\n",
      "lstat      0.030302\n",
      "medv       0.002556\n",
      "dtype: float64\n",
      "0.661655563609\n"
     ]
    }
   ],
   "source": [
    "print models.loc[12,\"model\"].params\n",
    "print models.loc[12,\"model\"].rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.92827304 -0.53382935 -0.1856728  -0.97065932  0.28088454  0.03738141\n",
      " -1.84895149  4.49652911 -0.06958163 -0.4725579  -0.72316063  0.96750015\n",
      " -1.60331888]\n",
      "0.453056847934\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import RidgeCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_std = scaler.fit_transform(X)\n",
    "ridge_cv = RidgeCV(alphas=[0.001, 0.01, 0.1, 1.0, 5, 7, 8.5, 8.7, 8.9, 8.995, 9, 9.25, 9.3,  9.5, 9.7, 10.0, 100, 1000])\n",
    "model_cv = ridge_cv.fit(X_std, y)\n",
    "print model_cv.coef_\n",
    "print ridge_cv.score(X_std,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.04074183 -0.43916991 -0.18914335 -1.18580599  0.29948192  0.03806506\n",
      " -2.06908831  5.10216051 -0.62159656 -0.58270034 -0.68739465  0.90092437\n",
      " -1.81984219]\n",
      "0.454009513354\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "lasso_cv = LassoCV(alphas=[0.001, 0.01, 0.1, 1.0, 5, 7, 8.5, 8.7, 8.9, 8.995, 9, 9.25, 9.3,  9.5, 9.7, 10.0, 100, 1000])\n",
    "model_lcv = lasso_cv.fit(X_std,y)\n",
    "print model_lcv.coef_\n",
    "print lasso_cv.score(X_std,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.015713985042872958, 0.36848743113535093, 0.36828233432338431, 0.45758542965026994, 0.46370396184248852, 0.46209774108169527, 0.46521536003832181, 0.46153466954177702, 0.49293600915250868, 0.49550475919938713, 0.50026824951139404, 0.5000246793017552, 0.50057953045400638, 0.50749067103523182, 0.50749067103523182, 0.50749067103523182, 0.50749067103523182, 0.50749067103523182, 0.50749067103523182, 0.50749067103523182]\n",
      "0.507490671035\n"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pca = PCA()\n",
    "regr = LinearRegression()\n",
    "X_r = pca.fit_transform(X_std)\n",
    "kf = model_selection.KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "r2d2 = []\n",
    "score = model_selection.cross_val_score(regr, np.ones((len(X_r),1)), y.ravel(), cv=kf, scoring='r2').mean()\n",
    "r2d2.append(score)\n",
    "\n",
    "for i in np.arange(1, 20):\n",
    "    score = model_selection.cross_val_score(regr, X_r[:,:i], y.ravel(), cv=kf, scoring='r2').mean()\n",
    "    r2d2.append(score)\n",
    "print r2d2\n",
    "print max(r2d2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that finding the best subset or using PCR produces the best results in terms of achieving a good R^2 value without overfitting. Ridge and Lasso seem to fare pretty abysmally here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Propose a model (or set of models) that seem to perform well on this data set, and justify your answer. Make sure that you are evaluating model performance using validation set error, crossvalidation, or some other reasonable alternative, as opposed to using training error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using the model generated by the best subset seems to work best. Taking the validation set R^2 value of .66 in comparison to the other tested models, I feel fairly confident in saying that this is the best model of the 4 for our purposes by a good margin.\n",
    "\n",
    "zn        -0.001278\n",
    "indus      0.029043\n",
    "chas       0.044097\n",
    "rm         0.166329\n",
    "age        0.002430\n",
    "dis       -0.005937\n",
    "rad        0.023421\n",
    "tax        0.001935\n",
    "ptratio   -0.047123\n",
    "black     -0.003340\n",
    "lstat      0.030302\n",
    "medv       0.002556\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Does your chosen model involve all of the features in the data set? Why or why not?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Yes, it does. Due to the monotonically decreasing values of AIC and BIC, I feel confident that the risk of overfitting is low. The R^2 value seems to increase by a couple of percentage point for every predictor included as well, so the model definitely seems to benefit from the added features. As a result, I chose to use all the features given to create my model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a written problem, supporting Problem 9 above.  Note that a lot of this has been solved in class, but it is good for you to try to do it again without referencing the class notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the Least Squares optimization problem, given data X and y ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $x_i$ represents the ith row of X and hence is a row-vector.  Hence $x_{iβ}$ represents the dot product between the p-length vectors $x_i$ and β. Derive a closed form solution (as wedid in class) for $ˆβ_{LS}$, by expanding out, taking the derivative and setting it equal to zero. It might be easiest to work in vector notation rather than deal with the individual $x_i$’s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the Ridge Regression problem ... Use the same approach as above to again derive a closed form expression for the solution, $ˆβ_R$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "![title](Q4.jpg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
