{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Karthik Konath (kk28699), Kyle Polansky (kpp446)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>EE 379K-DS Lab 6<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem we will use synthetic data sets to explore the bias-variance tradeoff incurred by using regularization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate data of the form: $y=Xβ+\\epsilon$, where X is an n×p matrix where n= 51,p= 50, and each $X_{ij}$ ∼N(0,1). Also, generate the noise according to $\\epsilon_i ∼N(0,1/4). Let β be the all ones vector (for simplicity)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By repeatedly doing this experiment and generating fresh data (fresh X, and y, and hence $\\epsilon$ – but make that you’re not reseting your random seed!) but keeping β fixed, you will estimatemany different solutions,ˆβ.  Estimate the mean and variance of ˆβ. Note that ˆβ is a vector, so for this exercise simply estimate the variance of a single component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use ridge regression, i.e., l2 regularization. Vary the regularization coefficient λ= 0.01,0.1,1,10,100 and repeat the above experiment. What do you observe? As you increase λ is the model becoming more simple or more complex? As you increase λ is performance becoming better or worse? Also compute LOOCV for each λ. How does the value of LOOCV, and in particular how it changes as λ varies, compare with what you observe for the explicitly computed variance?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read about the Bootstrap, and try to use it to compute the variance (as above), but with asingle copy of the data, rather than with many fresh copies of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2. Problem 9 from Chapter 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Predicting  the  number  of  applications  in  College)  Note  that  you  will  have  to  read  about  PCR(Principal Components Regression) and PLS (Partial Least Squares ) in the book, since we did notdiscuss these in class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In this exercise, we will predict the number of application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Split the data set into a training set and a test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import PLSRegression\n",
    "\n",
    "df = pd.read_csv(\"College.csv\", header = 0, index_col = 0)\n",
    "df.head()\n",
    "\n",
    "df.replace({\"Yes\" : 1, \"No\" : 0}, inplace = True)\n",
    "x = df.drop([\"Apps\"], axis = 1)\n",
    "y = df.loc[:,\"Apps\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Fit a linear model using least squares on the training set, and report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1010.6636061663704\n"
     ]
    }
   ],
   "source": [
    "fit = LinearRegression().fit(x_train, y_train)\n",
    "y_pred = fit.predict(x_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Fit a ridge regression model on the training set, with λ chosen by cross-validation. Report the test error obtained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1012.8559499061809\n"
     ]
    }
   ],
   "source": [
    "alphas = np.arange(0.001,10,.01)\n",
    "fit = RidgeCV(alphas = alphas).fit(x_train, y_train)\n",
    "y_pred = fit.predict(x_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(d) Fit a lasso model on the training set, with λ chosen by crossvalidation. Report the test error obtained, along with the number of non-zero coefficient estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1014.3092155895241\n",
      "12\n"
     ]
    }
   ],
   "source": [
    "fit = LassoCV(alphas = alphas).fit(x_train, y_train)\n",
    "y_pred = fit.predict(x_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "\n",
    "print(sum(fit.coef_ > 0.1) + sum(fit.coef_ < -0.1)) #coefficients less than .1 considered 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(e) Fit a PCR model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value of M selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1046.6227708719919\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "total_variance = 0\n",
    "\n",
    "for i in range(1,18):\n",
    "    pca = PCA(n_components = i, svd_solver = \"full\")\n",
    "    score = -1 * cross_val_score(pca, x, y, cv = 5).mean()\n",
    "    pca  = pca.fit(x_train, y_train)\n",
    "    if total_variance < .9:\n",
    "        total_variance += pca.explained_variance_ratio_[-1]\n",
    "        m = i\n",
    "\n",
    "fit = LinearRegression().fit(x_train.iloc[:,:m+1] , y_train)\n",
    "x_test_pcr = x_test.iloc[:,:m+1]\n",
    "y_pred = pcr.predict(x_test_pcr)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(f) Fit a PLS model on the training set, with M chosen by crossvalidation. Report the test error obtained, along with the value of M selected by cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3028.1645714290194\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "m = 0\n",
    "best_score = 0\n",
    "\n",
    "for i in range(1,18):\n",
    "    score = -1 * cross_val_score(PLSRegression(n_components = i), x, y, cv = 5).mean()\n",
    "    if score < best_score:\n",
    "        best_score = score\n",
    "        m = i\n",
    "    \n",
    "fit = PLSRegression(n_components = m).fit(x_train, y_train)\n",
    "y_pred = fit.predict(x_test)\n",
    "\n",
    "print(np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(g) Comment on the results obtained. How accurately can we predict the number of college applications received? Is there much difference among the test errors resulting from these five approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All of the models are roughly similar, with the exception of PLS which is significantly worse than the other models. In our case, the linear model has the lest rmse value, very closely followed by ridge and lasso. Using the linear model, college applications received can be estimated with a RMSE of roughly 1000."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 3. Problem 11 from Chapter 6."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(Predicting crime in Boston)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now try to predict per capita crime rate in the Boston data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Try out some of the regression methods explored in this chapter, such as best subset selection, the lasso, ridge regression, and PCR. Present and discuss results for the approaches that you consider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Propose a model (or set of models) that seem to perform well on this data set, and justify your answer. Make sure that you are evaluating model performance using validation set error, crossvalidation, or some other reasonable alternative, as opposed to using training error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(c) Does your chosen model involve all of the features in the data set? Why or why not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a written problem, supporting Problem 9 above.  Note that a lot of this has been solved in class, but it is good for you to try to do it again without referencing the class notes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the Least Squares optimization problem, given data X and y ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that $x_i$ represents the ith row of X and hence is a row-vector.  Hence $x_{iβ}$ represents the dot product between the p-length vectors $x_i$ and β. Derive a closed form solution (as wedid in class) for $ˆβ_{LS}$, by expanding out, taking the derivative and setting it equal to zero. It might be easiest to work in vector notation rather than deal with the individual $x_i$’s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now consider the Ridge Regression problem ... Use the same approach as above to again derive a closed form expression for the solution, $ˆβ_R$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
